{"cells":[{"metadata":{"id":"view-in-github"},"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/dmarinere/Team_Egypt_Corona/blob/master/Team_Egypt_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"},{"metadata":{"id":"eplvaJH0B2SE"},"cell_type":"markdown","source":"The task is to quantify the statistical significance of a public health policy introduced by African governments to slow down the spread of COVID-19.\nIn this Analysis, the goal is to understand the impact of Government interventions and forecasting COVID-19 Cases in Egypt. This task will aim to extend the paper ['The SIR Model for Spread of Disease']('https://www.maa.org/press/periodicals/loci/joma/the-sir-model-for-spread-of-disease-the-differential-equation-model') to our target country **EGYPT**"},{"metadata":{"id":"ny59Nb7VGUCt"},"cell_type":"markdown","source":"##  Table of Content \n\n1. [Installing and importing important library](https://colab.research.google.com/drive/1oEFgEA4H3qF3Hwe4k9VYIrtNOYkYO4IB#scrollTo=SbcloOmXn7QK&line=1&uniqifier=1)\n\n2. [Data Retrieval](https://colab.research.google.com/drive/1oEFgEA4H3qF3Hwe4k9VYIrtNOYkYO4IB#scrollTo=SbcloOmXn7QK&line=1&uniqifier=1)\n\n3. [Data Preprocessing](https://colab.research.google.com/drive/1oEFgEA4H3qF3Hwe4k9VYIrtNOYkYO4IB#scrollTo=WnNQvf3RMFL6&line=2&uniqifier=1)\n4. [Splitting our Dataset](https://colab.research.google.com/drive/1oEFgEA4H3qF3Hwe4k9VYIrtNOYkYO4IB#scrollTo=ny59Nb7VGUCt&line=7&uniqifier=1)\n\n5. [Introducing Policies](https://colab.research.google.com/drive/1oEFgEA4H3qF3Hwe4k9VYIrtNOYkYO4IB#scrollTo=XQt0w0QzN8cL&line=1&uniqifier=1)\n6. [Validating our Model and plotting](https://colab.research.google.com/drive/1oEFgEA4H3qF3Hwe4k9VYIrtNOYkYO4IB#scrollTo=dyDWMMQEifrp&line=1&uniqifier=1)\n\n7. [Prediction Plot](https://colab.research.google.com/drive/1oEFgEA4H3qF3Hwe4k9VYIrtNOYkYO4IB#scrollTo=S6IihZRNw2n-&line=1&uniqifier=1)"},{"metadata":{"id":"SbcloOmXn7QK"},"cell_type":"markdown","source":"# Importing Libraries \n\n#### We first have to import the latest version of **PYMC3** and also the **COVID-19** Library that are essential for this analysis"},{"metadata":{"id":"qTotJnQUq6-Q","trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/Priesemann-Group/covid19_inference.git\n!pip install git+https://github.com/pymc-devs/pymc3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"id":"ddpvffAsGUDB"},"cell_type":"markdown","source":"Then we import the libraries we just download and other important libraries that are essential\n"},{"metadata":{"id":"sVG4idcEGUDD","trusted":true},"cell_type":"code","source":"import datetime\nimport time as time_module\nimport sys\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport scipy.stats\nimport theano\nimport theano.tensor as tt\nimport pymc3 as pm\nimport arviz as az\nimport covid19_inference as cov19\nimport pickle \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"id":"7Zz2fdueGUDa"},"cell_type":"markdown","source":"\n# 2. Data retrieval\n\nThe next thing we want to do is load a dataset from reliable data sources.\nThere are multiple authentic data sources which can be found [here](https://covid19-inference.readthedocs.io/en/latest/doc/data_retrieval.html).\nIn this example we will use the JHU dataset, which comes from the John Hopkins University, we would use the COVID19 library for this. \n"},{"metadata":{"id":"A5uBPFaLGUDc","outputId":"ac062759-eeab-488e-c216-88b45047a8ef","trusted":true},"cell_type":"code","source":"jhu = cov19.data_retrieval.JHU()  # It is important to download the dataset!\njhu.download_all_available_data()\n# One could also parse True to the constructor of the class to force an auto download so we could retrieve data as they are upload from our source","execution_count":null,"outputs":[]},{"metadata":{"id":"P0U26VvJKhE7"},"cell_type":"markdown","source":"One could also parse True to the constructor of the class above to force an auto download so we could retrieve data as they are upload from our source"},{"metadata":{"id":"WnNQvf3RMFL6"},"cell_type":"markdown","source":"# 3. Data Preprocessing \n"},{"metadata":{"id":"EN9if7svGUDl"},"cell_type":"markdown","source":"\n\nWe can now access this downloaded data by the attribute that we are looking for and also in this case the specific country which is **Egypt** using some functions and filters that come with the JHU \n\n\nyou can learn more about the different filter methods [here](https://covid19-inference.readthedocs.io/en/latest/doc/data_retrieval.html#covid19_inference.data_retrieval.JHU.get_new).\n\n"},{"metadata":{"id":"dqmctCGfhLQ_"},"cell_type":"markdown","source":"We start with by filtering the time range we need to use for the analysis we would start from the first confirmed COVID19 case in  which was **14 February 2020**"},{"metadata":{"id":"ch4hJJjSGUDm","trusted":true},"cell_type":"code","source":"bd = datetime.datetime(2020, 2, 14)  # For the date filter from first confirmed case\ned = datetime.datetime.now() #Till today","execution_count":null,"outputs":[]},{"metadata":{"id":"vsVkON_MOJB_"},"cell_type":"markdown","source":"We then go ahead to retrieved the Total(Cumulative) number of confirmed cases and also the total number of new cases per day since this is possible and would make our analysis easier using the data we specified above."},{"metadata":{"id":"asqqHdfwGUDs","trusted":true},"cell_type":"code","source":"total_cases_obs = jhu.get_total(\n    value=\"confirmed\", country = 'Egypt', data_begin=bd, data_end=ed\n)\nnew_cases_obs = jhu.get_new(\n    value=\"confirmed\", country = 'Egypt', data_begin=bd, data_end=ed\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"xv_QdBDCO2n6"},"cell_type":"markdown","source":"I want to start with understanding the data and the number of days with no cases."},{"metadata":{"id":"Tbdaxxxf8MyC","trusted":true},"cell_type":"code","source":"nonew_cases= new_cases_obs[new_cases_obs == 0]","execution_count":null,"outputs":[]},{"metadata":{"id":"yaTQ0imO8SOW","outputId":"50d19595-5ef3-4b85-9b7a-1b0bbfdc5194","trusted":false},"cell_type":"code","source":"nonew_cases","execution_count":null,"outputs":[]},{"metadata":{"id":"1fACtI1QgNNQ"},"cell_type":"markdown","source":"> > We were told to look out for zeros in our number of cases but since i started my modelling from a 14th of March, there is only one zero to worry about which wouldn't affect our modelling and Prediction"},{"metadata":{"id":"_--NxkXxQD6F"},"cell_type":"markdown","source":"I would start my analysis from the time that the total number of cases in Egypt got to 100 as this would be a Indication that it has gotten to the stage of community spread and according to the model which i would use for my analysis signify that it would grow exponential and can be predicted more accurately."},{"metadata":{"id":"msiwYwRyQiSW"},"cell_type":"markdown","source":"This would be done by specifying that for the total number of cases we are only date where the cases are greater than 100"},{"metadata":{"id":"8gAsClDRgqm0"},"cell_type":"markdown","source":" >> Here is an overview of the cases"},{"metadata":{"id":"q89UMjcJwTAV","outputId":"d9d17835-3d75-4902-fbf6-7a6ee6d37bf5","trusted":false},"cell_type":"code","source":"total_cases_obs","execution_count":null,"outputs":[]},{"metadata":{"id":"ZSZ9LHKmUubv"},"cell_type":"markdown","source":"It is clear from this that the cummulative number of cases currently is **94,875** at 5th of August 2020"},{"metadata":{"id":"zX2FMXV9VcfX"},"cell_type":"markdown","source":"We would print the shape and dimension of our data\n\n\n\n"},{"metadata":{"id":"2SRUdUrCVYil","outputId":"01b56972-9712-424e-d9ea-7919b1f3acca","trusted":true},"cell_type":"code","source":"print(\"The Shape of total number of cases is\", total_cases_obs.shape[0],\n      \"rows\" )\nprint(\"The dimension of the total number of cases is\",total_cases_obs.ndim)","execution_count":null,"outputs":[]},{"metadata":{"id":"4aM2bFULZ3Rq"},"cell_type":"markdown","source":"This starts with removing any data that is less than 100 from the data set as explained previously, we would do this to both the total cases and the recorded daily cases"},{"metadata":{"id":"holtKNhDXWQn","outputId":"0e25f9d6-def0-431f-f644-d689ea0ec617","trusted":true},"cell_type":"code","source":"total_cases_obs =total_cases_obs[total_cases_obs > 99 ]\ntotal_cases_obs","execution_count":null,"outputs":[]},{"metadata":{"id":"8iipanAjbmYa"},"cell_type":"markdown","source":"using the day before the number of cases were greater than 100 which was **13-3-2020** we would retrieve only cases after that day also for new cases dataset"},{"metadata":{"id":"9gtUo8n0amEB","outputId":"d43660f4-e973-48a0-d048-8460d9635c09","trusted":true},"cell_type":"code","source":"new_cases_obs = new_cases_obs[new_cases_obs.index > '2020-03-13']\nnew_cases_obs","execution_count":null,"outputs":[]},{"metadata":{"id":"PRxu8ECKcGOm"},"cell_type":"markdown","source":"#Splitting our the dataset\n\n\n"},{"metadata":{"id":"B1axytByceFF"},"cell_type":"markdown","source":"We would split our dataset into training and test as was specified in the instruction given     \n**Training set**    \nIncludes all dates from the time the community transmission reaches 100 to July 25 2020.   \n**Validation set**   \nIncludes dates from 25 July 2020 to one final date in the covid19 cases data.  \n"},{"metadata":{"id":"vawtdp6QaJdt","trusted":true},"cell_type":"code","source":"#days before 25 of July we had already dealt with community transmission earlier\ntrain_total =  total_cases_obs[total_cases_obs.index < '2020-07-25']\ntrain_new = new_cases_obs[new_cases_obs.index < '2020-07-25']\n\n#days after 24th of july this would be used for the validation to compare \n#our prediction\ntest_total =  total_cases_obs[total_cases_obs.index > '2020-07-24']\ntest_new =  new_cases_obs[new_cases_obs.index > '2020-07-24']","execution_count":null,"outputs":[]},{"metadata":{"id":"EzQMvE7X23gn"},"cell_type":"markdown","source":"# Plot the training data together\n\n>    ### Sorry \n > > ### We have to create a model first\n# Creating a model \n\nNo no no, we can't jump to this now, we would have to start with specifying the different parameters, modelling our data and getting samples and prediction before we can even begin to plot anything,\nWe would start from trying to create a model\n\n\n\n"},{"metadata":{"id":"Lm2NSRZdCol5","outputId":"50946513-ed37-460c-e500-b81f7a182490","trusted":false},"cell_type":"code","source":"train_total","execution_count":null,"outputs":[]},{"metadata":{"id":"XQt0w0QzN8cL"},"cell_type":"markdown","source":"# Find the dates where your country introduced the following policies."},{"metadata":{"id":"q-tULNFboYN9"},"cell_type":"markdown","source":"The model parameters would be specified for different points, in my data we specified three different Change point where the government annouced some policies that we think were important to the trajectory of Coronavirus\n> 1. School closures and some work restrictions when the cummulative cases were 100 :   **March 15**\n> 2. Stay at Home and serious restrictions to religious gathering et al. \ncummulative cases were 900 :   **March 26**\n> 3. Reopening of the Economy in Egypt for Tourist : **July 1**\n\n > > We would be focusing on just this different change point we want to see how this affected the COVID-19 Spread in Egypt. "},{"metadata":{"id":"p-etNSWbGUDz"},"cell_type":"markdown","source":"\n\n## Creating the model\n\nFirst we need to set the priors for the change points and other configs.\n"},{"metadata":{"id":"yinWq2-jGUD0","trusted":true},"cell_type":"code","source":"diff_data_sim = 10  # should be significantly larger than the expected delay, in\n# order to always fit the same number of data points.\nnum_days_forecast = 10","execution_count":null,"outputs":[]},{"metadata":{"id":"AveT5EO1GUD6","trusted":true},"cell_type":"code","source":"# We set the priors for the changepoints here\nprior_date_mild_dist_begin = datetime.datetime(2020, 3, 15)\nprior_date_strong_dist_begin = datetime.datetime(2020, 3, 26)\nprior_date_reopen_ban_begin = datetime.datetime(2020, 7, 1)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"N7VkgghiGUD_","trusted":true},"cell_type":"code","source":"change_points = [\n    dict(\n        pr_mean_date_transient=prior_date_mild_dist_begin,\n        pr_sigma_date_transient=3,\n        pr_median_lambda=0.2,\n        pr_sigma_lambda=1,\n    ),\n    dict(\n        pr_mean_date_transient=prior_date_strong_dist_begin,\n        pr_sigma_date_transient=1.5,\n        pr_median_lambda=1 / 8,\n        pr_sigma_lambda=1,\n    ),\n    dict(\n        pr_mean_date_transient=prior_date_reopen_ban_begin,\n        pr_sigma_date_transient=1.5,\n        pr_median_lambda=1 / 16,\n        pr_sigma_lambda=1,\n     ),\n]","execution_count":null,"outputs":[]},{"metadata":{"id":"vUjePD1RGUEG","trusted":true},"cell_type":"code","source":"params_model = dict(\n    new_cases_obs=train_new[:],\n    #specifying when our data starts\n    data_begin=datetime.datetime(2020, 3, 14),\n    fcast_len=num_days_forecast,\n    diff_data_sim=diff_data_sim,\n    N_population=98e6,\n)\n# Median of the prior for the delay in case reporting, we assume 10 days\npr_delay = 10","execution_count":null,"outputs":[]},{"metadata":{"id":"y-8rp8zJGUEL"},"cell_type":"markdown","source":"\n\nThe model is specified in a context. Each function in this context\nhas access to the model parameters set.\n"},{"metadata":{"id":"aRKmY_Y6GUEN","outputId":"8c255d90-2390-4cec-9f81-3ade80dbab9f","trusted":true},"cell_type":"code","source":"with cov19.model.Cov19Model(**params_model) as this_model:\n    # Create the an array of the time dependent infection rate lambda\n    lambda_t_log = cov19.model.lambda_t_with_sigmoids(\n        pr_median_lambda_0=0.4,\n        pr_sigma_lambda_0=0.5,\n        change_points_list=change_points,  # The change point priors we constructed earlier\n        name_lambda_t=\"lambda_t\",  # Name for the variable in the trace (see later)\n    )\n\n    # set prior distribution for the recovery rate\n    mu = pm.Lognormal(name=\"mu\", mu=np.log(1 / 8), sigma=0.2)\n\n    # This builds a decorrelated prior for I_begin for faster inference.\n    # It is not necessary to use it, one can simply remove it and use the default argument\n    # for pr_I_begin in cov19.SIR\n    prior_I = cov19.model.uncorrelated_prior_I(\n        lambda_t_log=lambda_t_log,\n        mu=mu,\n        pr_median_delay=pr_delay,\n        name_I_begin=\"I_begin\",\n        name_I_begin_ratio_log=\"I_begin_ratio_log\",\n        pr_sigma_I_begin=2,\n        n_data_points_used=5,\n    )\n\n    # Use lambda_t_log and mu to run the SIR model\n    new_cases = cov19.model.SIR(\n        lambda_t_log=lambda_t_log,\n        mu=mu,\n        name_new_I_t=\"new_I_t\",\n        name_I_t=\"I_t\",\n        name_I_begin=\"I_begin\",\n        pr_I_begin=prior_I,\n    )\n\n    # Delay the cases by a lognormal reporting delay\n    new_cases = cov19.model.delay_cases(\n        cases=new_cases,\n        name_cases=\"delayed_cases\",\n        name_delay=\"delay\",\n        name_width=\"delay-width\",\n        pr_mean_of_median=pr_delay,\n        pr_sigma_of_median=0.2,\n        pr_median_of_width=0.3,\n    )\n\n    # Modulate the inferred cases by a abs(sin(x)) function, to account for weekend effects\n    # Also adds the \"new_cases\" variable to the trace that has all model features.\n    new_cases = cov19.model.week_modulation(\n        cases=new_cases,\n        name_cases=\"new_cases\",\n        name_weekend_factor=\"weekend_factor\",\n        name_offset_modulation=\"offset_modulation\",\n        week_modulation_type=\"abs_sine\",\n        pr_mean_weekend_factor=0.3,\n        pr_sigma_weekend_factor=0.5,\n        weekend_days=(5, 6),\n    )\n\n    # Define the likelihood, uses the new_cases_obs set as model parameter\n    cov19.model.student_t_likelihood(new_cases)","execution_count":null,"outputs":[]},{"metadata":{"id":"P0fVIHttvOYe","trusted":false},"cell_type":"code","source":"filename = \"/content/drive/My Drive/Colab Notebooks/model/SIRMore.pickled\"","execution_count":null,"outputs":[]},{"metadata":{"id":"rDtIA3IVDzv5","outputId":"244fb2cb-95f6-4856-8069-1c9bc3ee67ef","trusted":false},"cell_type":"code","source":"loaded_model = pickle.load(open(filename, 'rb'))","execution_count":null,"outputs":[]},{"metadata":{"id":"rK2uWMofqrX0","trusted":false},"cell_type":"code","source":"this_mode, trace = loaded_model[0], loaded_model[1]","execution_count":null,"outputs":[]},{"metadata":{"id":"DlaE3eiVC8us","outputId":"3b107acc-b041-4902-de03-6ca5c5749127","trusted":false},"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","execution_count":null,"outputs":[]},{"metadata":{"id":"xQQ69OXiGUER"},"cell_type":"markdown","source":"\n## MCMC sampling(Marcov Chain Monte Carlo )\n\nAfter the model is built and assigned different parameters, it is then sampled using an  [MCMC sampler](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo).![MCMC Explained](https://github.com/fonnesbeck/mcmc_pydata_london_2019/raw/99aaa2350a57a8e4866cd5510b3c0c4f81c80647/notebooks/images/Metropolis.png)\n\n\n\n\nThe number of parallel runs can be set with the argument `cores=`.\nIn particular, due to a bug in Theano, Windows users should set `cores=1`.\nThe sampling can take a long time but we would reduce the run and sample for this analysis\n\n"},{"metadata":{"id":"-AMT20hAGUER","outputId":"1300aa82-ad84-4d7a-8598-4b46dd07a0c2","trusted":true},"cell_type":"code","source":"trace = pm.sample(model=this_model, tune=500, draws=500, init=\"advi+adapt_diag\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace","execution_count":null,"outputs":[]},{"metadata":{"id":"Pb7bNb36TtBf","trusted":false},"cell_type":"code","source":"path_save_pickled = \"/content/drive/My Drive/Colab Notebooks/Week-3/Friday-Week3/\"\npickle.dump([this_model, trace], open(path_save_pickled + 'SEIR.pickled', 'wb'))\n","execution_count":null,"outputs":[]},{"metadata":{"id":"jkms_gdcGUEU"},"cell_type":"markdown","source":"\n# Plotting the Distribution of the posteriors and the priors \n\n\n### Distributions\n"},{"metadata":{"id":"zI-1Ajf8Ss80"},"cell_type":"markdown","source":"This function helps us plot the distribution very easily"},{"metadata":{"id":"kEcqAJzkjSfs","trusted":false},"cell_type":"code","source":"def plot_distributions(model, trace, color=None):\n    fig, axes = plt.subplots(6, 3, figsize=(6, 9.4))\n    axes[0, 2].set_visible(False)\n    axes[1, 2].set_visible(False)\n    left_vars = [\"weekend_factor\", \"mu\", \"lambda_0\", \"lambda_1\", \"lambda_2\", \"lambda_3\"]\n    mid_vars = [\"offset_modulation\",\"sigma_obs\",\"I_begin\",\"transient_day_1\",\"transient_day_2\",\"transient_day_3\"]\n    right_vars =  [\"delay\", \"transient_len_1\", \"transient_len_2\", \"transient_len_3\"]\n\n    for i, key in enumerate(left_vars):\n        cov19.plot._distribution(model, trace, key, ax=axes[i, 0], color=color)\n\n    for i, key in enumerate(mid_vars):\n        cov19.plot._distribution(model, trace, key, ax=axes[i, 1], color=color)\n\n    for i, key in enumerate(right_vars):\n        cov19.plot._distribution(model, trace, key, ax=axes[i+2, 2], color=color)\n\n    fig.tight_layout()\n\ndef plot_results(model, trace):\n    plot_distributions(model, trace)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"-64O20WSE7gK"},"cell_type":"markdown","source":"Here we would try to understand the mean and standard deviation of our parameter and also the Rhat also help us understand how well our model is doing, the farther it is from 1.00 the more careful we should be, we would need more time to train our model to get perfect score for the rhat."},{"metadata":{"id":"7VKvYA2NYZeY","outputId":"36bcb7ea-a52f-4bb7-ebe3-7e8aba13da4a","trusted":false},"cell_type":"code","source":"pm.summary(trace, varnames=['lambda_0','lambda_1', 'lambda_2','transient_day_1','transient_day_2',\n  'transient_len_1', 'transient_len_2', 'I_begin', 'delay',\n 'weekend_factor', 'sigma_obs'] )","execution_count":null,"outputs":[]},{"metadata":{"id":"jE84kmc_FovD"},"cell_type":"markdown","source":"This would help anyone seeing this understand a litle about how our model is structure and how some parameters connect"},{"metadata":{"id":"iX--rGf-mMAO","outputId":"5f8defb6-5af1-45a3-e99d-3914c250fc8a","trusted":false},"cell_type":"code","source":"from pymc3 import model_to_graphviz\n\nmodel_to_graphviz(this_model)","execution_count":null,"outputs":[]},{"metadata":{"id":"hdg7uAG-F5gt"},"cell_type":"markdown","source":"We would see here that the model has not been stabilized to make very accurate prediction, this is because we do not have sufficient resource to carry out the prediction for that time range currently, as it would take days, to do a more wholistic analysis, it is trying to form a distribution but has not yet been able to, because we didn't give it enough time"},{"metadata":{"id":"WbnM_h8ZZIq-","outputId":"5340b059-71fd-477e-dbdb-cf188abd4d5a","trusted":false},"cell_type":"code","source":"pm.traceplot(trace,  varnames=['lambda_0','lambda_1', 'lambda_2','transient_day_1','transient_day_2',\n  'transient_len_1', 'transient_len_2', 'I_begin', 'delay',\n 'weekend_factor', 'sigma_obs'] );","execution_count":null,"outputs":[]},{"metadata":{"id":"2hWKort-F4S4"},"cell_type":"markdown","source":"Here we plot results from our Analysis, this shows fitted our model is to the sample \n\n\n"},{"metadata":{"id":"3b7nP29_GUEh","outputId":"efd76b2c-acd8-4ca8-f64d-7aa200129bbc","trusted":false},"cell_type":"code","source":"plot_results(model=this_model, trace=trace)","execution_count":null,"outputs":[]},{"metadata":{"id":"32rO6i51GUEl"},"cell_type":"markdown","source":"\n### Timeseries\ntimeseries overview, for now needs an offset variable to get cumulative cases\n"},{"metadata":{"id":"tl8I5dIQGUEm","outputId":"09381838-d8a1-40c0-f8ca-021d33a8ddd6","trusted":false},"cell_type":"code","source":"fig, axes = cov19.plot.timeseries_overview(this_model, trace)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"dyDWMMQEifrp"},"cell_type":"markdown","source":"# Our Validation and Plot"},{"metadata":{"id":"1vpoociAid8D","trusted":false},"cell_type":"code","source":"y_fcast, x_fcast = cov19.plot._get_array_from_trace_via_date(\n        this_model, trace, \"new_cases\", this_model.fcast_begin, this_model.fcast_end\n    )","execution_count":null,"outputs":[]},{"metadata":{"id":"bAZpwaBOiwWM"},"cell_type":"markdown","source":"Here is our First Prediction while testing the data, we would compare this to the original data, since our model account for unreported values we would say this may be a near accurate analysis"},{"metadata":{"id":"Z-l2eJ5yieDb","outputId":"2c49f747-15d6-40e1-80b0-692216f298f8","trusted":false},"cell_type":"code","source":"cov19.plot._timeseries(test_new[:10].index, test_new[:10], what=\"data\")\ncov19.plot._timeseries(x_fcast, y_fcast[0], what=\"fcast\")\nplt.tight_layout()\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"id":"_tPBgZGpFE9I"},"cell_type":"markdown","source":"> >There is a similar patteren in both the test and the predict but the predictions seems to catch up slowly."},{"metadata":{"id":"Am6k7UNQx3qG"},"cell_type":"markdown","source":"I added some change point to this to make the prediction more accurate\n\n> Here we are trying to predict for future day till 10th of August \n\n"},{"metadata":{"id":"2Ijs6hi7xwSu","trusted":false},"cell_type":"code","source":"prior_date_reopen_begin3 = datetime.datetime(2020, 7, 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"HXsVWlg1xL-7","trusted":false},"cell_type":"code","source":"change_points = [\n    dict(\n        pr_mean_date_transient=prior_date_mild_dist_begin,\n        pr_sigma_date_transient=3,\n        pr_median_lambda=0.2,\n        pr_sigma_lambda=1,\n    ),\n    dict(\n        pr_mean_date_transient=prior_date_strong_dist_begin,\n        pr_sigma_date_transient=1.5,\n        pr_median_lambda=1 / 8,\n        pr_sigma_lambda=1,\n    ),\n    dict(\n        pr_mean_date_transient=prior_date_reopen_ban_begin,\n        pr_sigma_date_transient=1.5,\n        pr_median_lambda=1 / 12,\n        pr_sigma_lambda=1,\n     ),\n    dict(\n      pr_mean_date_transient=prior_date_reopen_begin3,\n        pr_sigma_date_transient=1.5,\n        pr_median_lambda=1 / 16,\n        pr_sigma_lambda=1,\n     ),\n]","execution_count":null,"outputs":[]},{"metadata":{"id":"TaBBJGH_uZgp","trusted":false},"cell_type":"code","source":"params_model = dict(\n    new_cases_obs=new_cases_obs[:],\n    #specifying when our data starts\n    data_begin=datetime.datetime(2020, 3, 14),\n    fcast_len=10,\n    diff_data_sim=diff_data_sim,\n    N_population=98e6,\n)\n# Median of the prior for the delay in case reporting, we assume 10 days\npr_delay = 10","execution_count":null,"outputs":[]},{"metadata":{"id":"w0oLp6BrwR_V"},"cell_type":"markdown","source":"Creating and specifying the model Parameters"},{"metadata":{"id":"i6cZpCwWwVE2","outputId":"91a0558b-0177-419d-97d7-3c8f40bff9fc","trusted":false},"cell_type":"code","source":"with cov19.model.Cov19Model(**params_model) as fore_model:\n    # Create the an array of the time dependent infection rate lambda\n    lambda_t_log = cov19.model.lambda_t_with_sigmoids(\n        pr_median_lambda_0=0.4,\n        pr_sigma_lambda_0=0.5,\n        change_points_list=change_points,  # The change point priors we constructed earlier\n        name_lambda_t=\"lambda_t\",  # Name for the variable in the trace (see later)\n    )\n\n    # set prior distribution for the recovery rate\n    mu = pm.Lognormal(name=\"mu\", mu=np.log(1 / 8), sigma=0.2)\n\n    # This builds a decorrelated prior for I_begin for faster inference.\n    # It is not necessary to use it, one can simply remove it and use the default argument\n    # for pr_I_begin in cov19.SIR\n    prior_I = cov19.model.uncorrelated_prior_I(\n        lambda_t_log=lambda_t_log,\n        mu=mu,\n        pr_median_delay=pr_delay,\n        name_I_begin=\"I_begin\",\n        name_I_begin_ratio_log=\"I_begin_ratio_log\",\n        pr_sigma_I_begin=2,\n        n_data_points_used=5,\n    )\n\n    # Use lambda_t_log and mu to run the SIR model\n    new_cases = cov19.model.SIR(\n        lambda_t_log=lambda_t_log,\n        mu=mu,\n        name_new_I_t=\"new_I_t\",\n        name_I_t=\"I_t\",\n        name_I_begin=\"I_begin\",\n        pr_I_begin=prior_I,\n    )\n\n    # Delay the cases by a lognormal reporting delay\n    new_cases = cov19.model.delay_cases(\n        cases=new_cases,\n        name_cases=\"delayed_cases\",\n        name_delay=\"delay\",\n        name_width=\"delay-width\",\n        pr_mean_of_median=pr_delay,\n        pr_sigma_of_median=0.2,\n        pr_median_of_width=0.3,\n    )\n\n    # Modulate the inferred cases by a abs(sin(x)) function, to account for weekend effects\n    # Also adds the \"new_cases\" variable to the trace that has all model features.\n    new_cases = cov19.model.week_modulation(\n        cases=new_cases,\n        name_cases=\"new_cases\",\n        name_weekend_factor=\"weekend_factor\",\n        name_offset_modulation=\"offset_modulation\",\n        week_modulation_type=\"abs_sine\",\n        pr_mean_weekend_factor=0.3,\n        pr_sigma_weekend_factor=0.5,\n        weekend_days=(5, 6),\n    )\n\n    # Define the likelihood, uses the new_cases_obs set as model parameter\n    cov19.model.student_t_likelihood(new_cases)","execution_count":null,"outputs":[]},{"metadata":{"id":"FV-6VEWpyaFU","trusted":false},"cell_type":"code","source":"trace2 = pm.sample(model=fore_model, tune=30, draws=100, init=\"advi+adapt_diag\", cores = 16)","execution_count":null,"outputs":[]},{"metadata":{"id":"DDAKfkxrymki","trusted":false},"cell_type":"code","source":"#save our model so we can use it again for future analysis\npath_save_pickled = \"/content/drive/My Drive/Colab Notebooks/model/\"\npickle.dump([fore_model, trace2], open(path_save_pickled + 'SIR3.pickled', 'wb'))\n","execution_count":null,"outputs":[]},{"metadata":{"id":"kmTHoydlqnC2","trusted":false},"cell_type":"code","source":"filename =\"/content/drive/My Drive/Colab Notebooks/model/SIR3.pickled\"\nmy_model = pickle.load(open(filename, 'rb'))","execution_count":null,"outputs":[]},{"metadata":{"id":"BnfBnQpfrCcB","trusted":false},"cell_type":"code","source":"fore_model, trace2 = my_model[0], my_model[1]","execution_count":null,"outputs":[]},{"metadata":{"id":"l74YyKu4A08z","outputId":"b6cc8996-2ce1-4de0-d7c9-f152b0ebb57a","trusted":false},"cell_type":"code","source":"fig, axes = cov19.plot.timeseries_overview(fore_model, trace2)","execution_count":null,"outputs":[]},{"metadata":{"id":"ilN00MUaTRlO","outputId":"1d92bed4-2d6c-4f75-a3d4-d19f0f194ed9","trusted":false},"cell_type":"code","source":"plot_results(model=fore_model, trace=trace2)","execution_count":null,"outputs":[]},{"metadata":{"id":"1WN71Q7kwp9g"},"cell_type":"markdown","source":"Predicted cases for next week for egypt "},{"metadata":{"id":"be7N4HrQdH5y","trusted":false},"cell_type":"code","source":"y_fcast, x_fcast = cov19.plot._get_array_from_trace_via_date(\n        fore_model, trace2, \"new_cases\", fore_model.fcast_begin, fore_model.fcast_end\n    )","execution_count":null,"outputs":[]},{"metadata":{"id":"S6IihZRNw2n-","outputId":"e3dc6f57-8e71-4ec2-cb23-55e8a63a6216","trusted":false},"cell_type":"code","source":"cov19.plot._timeseries(x_fcast, y_fcast[0], what=\"fcast\")\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"id":"ElnR3KfKxSCs","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}